{
 "metadata": {
  "name": "",
  "signature": "sha256:20c765cfa71383d96c2be2cd548237c9004c9e932f2f3233db8a9fa83f45e493"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "from sklearn import datasets, linear_model\n",
      "import matplotlib.pyplot as plt\n",
      "import statsmodels.api as sm\n",
      "def stats(y_true,y_pred):\n",
      "    \n",
      "    from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
      "    print \"-----------EVALUATION STATISTICS------------\"\n",
      "    print 'Mean absolute Error : ', mean_absolute_error(test_Y.values, y_pred)\n",
      "    print 'Mean squared Error : ', mean_squared_error(y_true, y_pred)\n",
      "    print 'R2 score : ', r2_score(y_true, y_pred)\n",
      "#actual data to amke predictions on\n",
      "df_real_32_data = pd.read_csv('../data/celebrities_32_final.csv', error_bad_lines=False)\n",
      "df_real_32_data['LifeExpnAge'] = df_real_32_data['LifeExpectancy']+df_real_32_data['Age']\n",
      "df_real_32_data_X = df_real_32_data[['DOB','LifeExpnAge','gender','nationality_no', 'Politician', 'Diplomat', 'Evangelist', 'Business magnate', 'Astronaut', 'Musician','Physicist','Actor','Guitarist','Singer','Pianist']]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read and filter data\n",
      "df_data2 = pd.read_csv('../data/../data/finaldata_profession_corrected_dob.csv', error_bad_lines=False, delimiter='~')\n",
      "#df_data2 = df_data2[df_data2.DOB1 > 1890]\n",
      "#df_data2 = df_data2[df_data2.Age > 35]\n",
      "#df_data2 = df_data2[df_data2.Age < 120]\n",
      "df_data2.to_csv('dataforsravnathi.csv')\n",
      "df_data = pd.read_csv('../data/freebasedata_profession.csv', error_bad_lines=False, delimiter='~')\n",
      "df_data2['LifeExpnAge'] = df_data2['LifeExpectancy']+df_data2['Age'] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/numexpr/necompiler.py:742: DeprecationWarning: using `oa_ndim == 0` when `op_axes` is NULL is deprecated. Use `oa_ndim == -1` or the MultiNew iterator for NumPy <1.8 compatibility\n",
        "  return compiled_ex(*arguments, **kwargs)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#clean data\n",
      "print df_data2.shape\n",
      "print df_data2.columns\n",
      "#remving Nans and NOnes\n",
      "df_data2 = df_data2.replace('unknown', np.nan)\n",
      "df_data2 = df_data2.replace('none', np.nan)\n",
      "df_data2=df_data2.fillna(df_data2.median())\n",
      "print df_data2.shape\n",
      "print df_data2.columns\n",
      "#removing NaN values\n",
      "df_data2 = df_data2.replace('unknown', np.nan)\n",
      "df_data2 = df_data2.replace('none', np.nan)\n",
      "df_data2 = df_data2.fillna(df_data2.median())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "Cannot create BlockManager._ref_locs because block [ObjectBlock: [Name], 1 x 167480, dtype: object] with duplicate items [Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Unnamed: 0.1', u'Name', u'/people/cause_of_death/parent_cause_of_death', u'/people/cause_of_death/includes_causes_of_death', u'/people/cause_of_death/people', u'DOD', u'/people/deceased_person/place_of_death', u'/people/deceased_person/cause_of_death', u'/people/deceased_person/date_of_cremation', u'/people/deceased_person/place_of_cremation', u'/people/deceased_person/date_of_burial', u'/people/deceased_person/place_of_burial', u'/people/ethnicity/included_in_group', u'/people/ethnicity/includes_groups', u'/people/ethnicity/geographic_distribution', u'/people/ethnicity/languages_spoken', u'/people/ethnicity/population', u'/people/ethnicity/people', u'/people/family_name/people_with_this_family_name', u'/people/group/member', u'/people/measured_person/measurements', u'/people/measured_person/sizes', u'DOB', u'/people/person/place_of_birth', u'/people/person/nationality', u'/people/person/gender', u'/people/person/profession', u'/people/person/religion', u'/people/person/ethnicity', u'/people/person/parents', u'/people/person/children', u'/people/person/sibling_s', u'/people/person/spouse_s', u'/people/person/employment_history', u'/people/person/education', u'/people/person/metaweb_user_s', u'/people/person/signature', u'/people/person/height_meters', u'/people/person/weight_kg', u'/people/person/quotations', u'/people/person/places_lived', u'/people/person/quotationsbook_id', u'/people/person/age', u'/people/person/tvrage_id', u'/people/person/notable_professions', u'/people/person/languages', u'/people/person/group', u'/people/professional_field/professions_in_this_field', u'/people/profession/people_with_this_profession', u'/people/profession/specialization_of', u'/people/profession/specializations', u'/people/profession/part_of_professional_field', u'Unnamed: 51', u'LifeExpectancy', u'Age', u'Probability', u'profession', u'gender', u'nationality', u'nationality_no', u'Politician', u'Pope-elect', u'Diplomat', u'Evangelist', u'Business magnate', u'Astronaut', u'Musician', u'Physicist', u'Actress', u'Actor', u'Guitarist', u'Singer', u'Pianist', u'DOB1', u'DOD1', u'LifeExpnAge'], dtype='object')] does not have _ref_locs set",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-2cec197c8e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdf_data2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#remving Nans and NOnes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_data2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unknown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_data2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_data2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_data2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method, axis)\u001b[0m\n\u001b[1;32m   2424\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'convert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m         bm = self.__class__(result_blocks, axes or self.axes,\n\u001b[0;32m-> 2385\u001b[0;31m                             do_integrity_check=do_integrity_check)\n\u001b[0m\u001b[1;32m   2386\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;31m# we have a duplicate items index, setup the block maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2038\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_ref_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_refs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_set_ref_locs\u001b[0;34m(self, labels, do_refs)\u001b[0m\n\u001b[1;32m   2176\u001b[0m                             \u001b[0;34m'Cannot create BlockManager._ref_locs because '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m                             \u001b[0;34m'block [%s] with duplicate items [%s] does not '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m                             'have _ref_locs set' % (block, labels))\n\u001b[0m\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m                     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_create_block_in_items_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAssertionError\u001b[0m: Cannot create BlockManager._ref_locs because block [ObjectBlock: [Name], 1 x 167480, dtype: object] with duplicate items [Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Unnamed: 0.1', u'Name', u'/people/cause_of_death/parent_cause_of_death', u'/people/cause_of_death/includes_causes_of_death', u'/people/cause_of_death/people', u'DOD', u'/people/deceased_person/place_of_death', u'/people/deceased_person/cause_of_death', u'/people/deceased_person/date_of_cremation', u'/people/deceased_person/place_of_cremation', u'/people/deceased_person/date_of_burial', u'/people/deceased_person/place_of_burial', u'/people/ethnicity/included_in_group', u'/people/ethnicity/includes_groups', u'/people/ethnicity/geographic_distribution', u'/people/ethnicity/languages_spoken', u'/people/ethnicity/population', u'/people/ethnicity/people', u'/people/family_name/people_with_this_family_name', u'/people/group/member', u'/people/measured_person/measurements', u'/people/measured_person/sizes', u'DOB', u'/people/person/place_of_birth', u'/people/person/nationality', u'/people/person/gender', u'/people/person/profession', u'/people/person/religion', u'/people/person/ethnicity', u'/people/person/parents', u'/people/person/children', u'/people/person/sibling_s', u'/people/person/spouse_s', u'/people/person/employment_history', u'/people/person/education', u'/people/person/metaweb_user_s', u'/people/person/signature', u'/people/person/height_meters', u'/people/person/weight_kg', u'/people/person/quotations', u'/people/person/places_lived', u'/people/person/quotationsbook_id', u'/people/person/age', u'/people/person/tvrage_id', u'/people/person/notable_professions', u'/people/person/languages', u'/people/person/group', u'/people/professional_field/professions_in_this_field', u'/people/profession/people_with_this_profession', u'/people/profession/specialization_of', u'/people/profession/specializations', u'/people/profession/part_of_professional_field', u'Unnamed: 51', u'LifeExpectancy', u'Age', u'Probability', u'profession', u'gender', u'nationality', u'nationality_no', u'Politician', u'Pope-elect', u'Diplomat', u'Evangelist', u'Business magnate', u'Astronaut', u'Musician', u'Physicist', u'Actress', u'Actor', u'Guitarist', u'Singer', u'Pianist', u'DOB1', u'DOD1', u'LifeExpnAge'], dtype='object')] does not have _ref_locs set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(167480, 78)\n",
        "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Unnamed: 0.1', u'Name', u'/people/cause_of_death/parent_cause_of_death', u'/people/cause_of_death/includes_causes_of_death', u'/people/cause_of_death/people', u'DOD', u'/people/deceased_person/place_of_death', u'/people/deceased_person/cause_of_death', u'/people/deceased_person/date_of_cremation', u'/people/deceased_person/place_of_cremation', u'/people/deceased_person/date_of_burial', u'/people/deceased_person/place_of_burial', u'/people/ethnicity/included_in_group', u'/people/ethnicity/includes_groups', u'/people/ethnicity/geographic_distribution', u'/people/ethnicity/languages_spoken', u'/people/ethnicity/population', u'/people/ethnicity/people', u'/people/family_name/people_with_this_family_name', u'/people/group/member', u'/people/measured_person/measurements', u'/people/measured_person/sizes', u'DOB', u'/people/person/place_of_birth', u'/people/person/nationality', u'/people/person/gender', u'/people/person/profession', u'/people/person/religion', u'/people/person/ethnicity', u'/people/person/parents', u'/people/person/children', u'/people/person/sibling_s', u'/people/person/spouse_s', u'/people/person/employment_history', u'/people/person/education', u'/people/person/metaweb_user_s', u'/people/person/signature', u'/people/person/height_meters', u'/people/person/weight_kg', u'/people/person/quotations', u'/people/person/places_lived', u'/people/person/quotationsbook_id', u'/people/person/age', u'/people/person/tvrage_id', u'/people/person/notable_professions', u'/people/person/languages', u'/people/person/group', u'/people/professional_field/professions_in_this_field', u'/people/profession/people_with_this_profession', u'/people/profession/specialization_of', u'/people/profession/specializations', u'/people/profession/part_of_professional_field', u'Unnamed: 51', u'LifeExpectancy', u'Age', u'Probability', u'profession', u'gender', u'nationality', u'nationality_no', u'Politician', u'Pope-elect', u'Diplomat', u'Evangelist', u'Business magnate', u'Astronaut', u'Musician', u'Physicist', u'Actress', u'Actor', u'Guitarist', u'Singer', u'Pianist', u'DOB1', u'DOD1', u'LifeExpnAge'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#set X and Y and clean\n",
      "#extracting fields for regression model\n",
      "df_data_X=pd.concat([df_data2['DOB1'], df_data2['LifeExpnAge'],df_data2['gender'],df_data2['nationality_no'],df_data2['Politician'],df_data2['Diplomat'],df_data2['Evangelist'],df_data2['Business magnate'],df_data2['Astronaut'],df_data2['Musician'],df_data2['Physicist'],df_data2['Actor'],df_data2['Guitarist'],df_data2['Singer'],df_data2['Pianist']],axis=1)\n",
      "df_data_Y=pd.concat([df_data2['DOD1']],axis=1)\n",
      "msk = np.random.rand(len(df_data2)) < 0.8\n",
      "train_X = df_data_X[msk]\n",
      "test_X = df_data_X[~msk]\n",
      "train_Y = df_data_Y[msk]\n",
      "test_Y = df_data_Y[~msk]\n",
      "train_X = train_X.replace('unknown', np.nan)\n",
      "train_X = train_X.replace('none', np.nan)\n",
      "train_X=train_X.fillna(train_X.median())\n",
      "test_X = test_X.replace('unknown', np.nan)\n",
      "test_X = test_X.replace('none', np.nan)\n",
      "test_X= test_X.fillna(test_X.median())\n",
      "test_Y = test_Y.replace('unknown', np.nan)\n",
      "test_Y = test_Y.replace('none', np.nan)\n",
      "test_Y= test_Y.fillna(test_Y.median())\n",
      "train_Y = train_Y.replace('unknown', np.nan)\n",
      "train_Y = train_Y.replace('none', np.nan)\n",
      "train_Y=train_Y.fillna(train_Y.median())\n",
      "print train_X.shape\n",
      "print train_Y.shape\n",
      "print test_X.shape\n",
      "print test_Y.shape\n",
      "test_X.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(133877, 15)\n",
        "(133877, 1)\n",
        "(33603, 15)\n",
        "(33603, 1)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Index([u'DOB1', u'LifeExpnAge', u'gender', u'nationality_no', u'Politician', u'Diplomat', u'Evangelist', u'Business magnate', u'Astronaut', u'Musician', u'Physicist', u'Actor', u'Guitarist', u'Singer', u'Pianist'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linearRegressionOLS(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import linear_model\n",
      "    regr = linear_model.LinearRegression(normalize=True,fit_intercept=False)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\"\n",
      "          % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    # Plot outputs\n",
      "    fig = plt.figure(figsize=(20, 16))\n",
      "    ax = fig.add_subplot(1,1,1)\n",
      "    ax.scatter(test_Y.values, regr.predict(test_X.values),  color='blue')\n",
      "    #plt.plot(test_X.values, regr.predict(test_X.values), color='blue', linewidth=3)\n",
      "    plt.xticks(fontsize=22)\n",
      "    plt.yticks(fontsize=22)\n",
      "    ax.set_xlabel('Actual year of Death', fontsize=20)\n",
      "    ax.set_ylabel('Predicted year of Death', fontsize=20)\n",
      "    ax.set_title('Prection vs Actual YOD - Evaluation', fontsize=20)\n",
      "    plt.show()\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "def ridge_regression(train_X,train_Y,test_X,test_Y):\n",
      "    '''Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a \n",
      "    penalty on the size of coefficients. The ridge coefficients minimize a penalized residual sum of squares,\n",
      "    Here, \\alpha \\geq 0 is a complexity parameter that controls the amount of shrinkage: \n",
      "    the larger the value of \\alpha, the greater the amount of shrinkage and thus the coefficients become \n",
      "    more robust to collinearity.'''\n",
      "    from sklearn import linear_model\n",
      "    n_alphas = 200\n",
      "    alphas = np.logspace(-10, -2, n_alphas)\n",
      "    regr = linear_model.Ridge(normalize=True,alpha=1.0,fit_intercept=False)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\"\n",
      "          % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    '''# Plot outputs\n",
      "    ax = plt.gca()\n",
      "    ax.set_color_cycle(['b', 'r', 'g', 'c', 'k', 'y', 'm'])\n",
      "    ax.plot(alphas, coefs)\n",
      "    ax.set_xscale('log')\n",
      "    ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
      "    plt.xlabel('alpha')\n",
      "    plt.ylabel('weights')\n",
      "    plt.title('Ridge coefficients as a function of the regularization')\n",
      "    plt.axis('tight')\n",
      "    plt.show()'''\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def lasso_regression(train_X,train_Y,test_X,test_Y):\n",
      "    '''The Lasso is a linear model that estimates sparse coefficients. It is useful in some contexts \n",
      "    due to its tendency to prefer solutions with fewer parameter values, effectively reducing the \n",
      "    number of variables upon which the given solution is dependent. For this reason, the Lasso and \n",
      "    its variants are fundamental to the field of compressed sensing. Under certain conditions, it \n",
      "    can recover the exact set of non-zero weights'''\n",
      "    from sklearn import linear_model\n",
      "    regr = linear_model.Lasso(normalize=True,alpha=0.1,fit_intercept=False)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\"\n",
      "          % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def elastic_net(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import linear_model\n",
      "    regr = linear_model.ElasticNet(normalize=True,fit_intercept=False)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\" % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def lasso_lars(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import linear_model\n",
      "    regr = linear_model.LassoLars(normalize=True,fit_intercept=False)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\"\n",
      "          % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def bayseian_ridge(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import linear_model\n",
      "    regr = linear_model.BayesianRidge(normalize=True,fit_intercept=False,compute_score=True)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    #print(\"Residual sum of squares: %.2f\" % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    #print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def ARD(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import linear_model\n",
      "    regr = linear_model.ARDRegression(normalize=True,fit_intercept=False)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\" % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "def SGD_regression(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import linear_model\n",
      "    regr = linear_model.SGDRegressor(fit_intercept=False)\n",
      "    regr.fit(train_X.values, train_Y.values)\n",
      "    # The coefficients\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\"\n",
      "          % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def poly(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn.preprocessing import PolynomialFeatures\n",
      "    from sklearn.linear_model import LinearRegression\n",
      "    from sklearn.pipeline import Pipeline\n",
      "    model = Pipeline([('poly', PolynomialFeatures(degree=3)), ('linear', LinearRegression(fit_intercept=False))])\n",
      "    model = model.fit(train_X,train_Y)\n",
      "    print model.named_steps['linear'].coef_\n",
      "    y_pred = model.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "'''\n",
      "def SVR(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import svm\n",
      "    regr = svm.SVR()\n",
      "    regr.fit(train_X.values,train_Y.values.ravel())\n",
      "    print ('Columns : \\n', train_X.columns)\n",
      "    print('Coefficients: \\n', regr.coef_)\n",
      "    # The mean square error\n",
      "    print ('Intercept : ', regr.intercept_)\n",
      "    print(\"Residual sum of squares: %.2f\"\n",
      "          % np.mean((regr.predict(test_X) - test_Y) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    #predictions\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    #df_real_32_data.columns\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "'''\n",
      "def KNN(train_X, train_Y, test_X, test_Y):\n",
      "    from sklearn.neighbors import KNeighborsRegressor\n",
      "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
      "    neigh.fit(train_X, train_Y) \n",
      "    print(\"Residual sum of squares: %.2f\" % np.mean((neigh.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % neigh.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,neigh.predict(test_X.values))\n",
      "    y_pred = neigh.predict(df_real_32_data_X)\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    distances, indices = neigh.kneighbors(test_X)\n",
      "    print indices.shape\n",
      "    print indices\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def decison_tree(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn import tree\n",
      "    regr = tree.DecisionTreeRegressor()\n",
      "    regr = regr.fit(train_X.values,train_Y.values)\n",
      "    print(\"Residual sum of squares: %.2f\" % np.mean((regr.predict(test_X.values) - test_Y.values) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X.values, test_Y.values))\n",
      "    stats(test_Y.values,regr.predict(test_X.values))\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n",
      "\n",
      "def SVR(train_X,train_Y,test_X,test_Y):\n",
      "    from sklearn.svm import SVR\n",
      "    c=1.0\n",
      "    regr =SVR(C=c, epsilon=0.2)\n",
      "    print (test_Y.shape)\n",
      "    test_Y=np.ravel(test_Y)\n",
      "    train_Y=np.ravel(train_Y)\n",
      "    regr = regr.fit(train_X.values,train_Y)\n",
      "    print(\"Residual sum of squares: %.2f\" % np.mean((regr.predict(test_X) - test_Y) ** 2))\n",
      "    # Explained variance score: 1 is perfect prediction\n",
      "    print('Variance score: %.2f' % regr.score(test_X, test_Y))\n",
      "    stats(test_Y,regr.predict(test_X))\n",
      "    y_pred = regr.predict(df_real_32_data_X)\n",
      "    df_real_32_data['pred_DOD'] = abs(y_pred)\n",
      "    print df_real_32_data[['Name','Age','pred_DOD','LifeExpnAge','Occupation']].sort(columns='pred_DOD', ascending=True).to_string()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_X=train_X[:10]\n",
      "train_Y=train_Y[:10]\n",
      "test_X=test_X[:5]\n",
      "test_Y=test_Y[:5]\n",
      "SVR(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5, 1)\n",
        "Residual sum of squares: 9942.45\n",
        "Variance score: -0.01\n",
        "-----------EVALUATION STATISTICS------------\n",
        "Mean absolute Error :  75.1677005787\n",
        "Mean squared Error :  9942.44523004\n",
        "R2 score :  -0.0144358542473\n",
        "                          Name  Age     pred_DOD  LifeExpnAge        Occupation\n",
        "0           Queen Elizabeth II   88  1934.499928        93.56        Politician\n",
        "29              Keith Richards   70  1934.499928        84.07          Musician\n",
        "28                 Mick Jagger   71  1934.499928        84.40          Musician\n",
        "27             Jerry Lee Lewis   79  1934.499928        87.63            Singer\n",
        "26                 Chuck Berry   88  1934.499928        92.64         Guitarist\n",
        "25                Kirk Douglas   97  1934.499928        99.47             Actor\n",
        "24              Clint Eastwood   84  1934.499928        90.21             Actor\n",
        "23                   B.B. King   89  1934.499928        93.30          Musician\n",
        "20               Dick van Dyke   88  1934.499928        92.64             Actor\n",
        "19                   Doris Day   90  1934.499928        94.80           Actress\n",
        "18             Stephen Hawking   72  1934.499928        84.75         Physicist\n",
        "17              Charles Manson   79  1934.499928        87.63          Musician\n",
        "16                  John Glenn   93  1934.499928        96.20         Astronaut\n",
        "30                  Abe Vigoda   93  1934.499928        96.20             Actor\n",
        "15                 Dick Cheney   73  1934.499928        85.12        Politician\n",
        "13           Rev. Billy Graham   96  1934.499928        98.62        Evangelist\n",
        "1   George Herbert Walker Bush   90  1934.499928        93.99        Politician\n",
        "2                 Jimmy Carter   90  1934.499928        93.99        Politician\n",
        "3                 Fidel Castro   88  1934.499928        92.64        Politician\n",
        "4                Pope Benedict   87  1934.499928        92.00        Pope-elect\n",
        "5                Robert Mugabe   90  1934.499928        93.99        Politician\n",
        "6                 Shimon Peres   91  1934.499928        94.70        Politician\n",
        "14              Rupert Murdoch   83  1934.499928        89.65  Business magnate\n",
        "7                 Ali Khamenei   75  1934.499928        85.89        Politician\n",
        "8                Hosni Mubarak   86  1934.499928        91.38        Politician\n",
        "9               Helmut Schmidt   95  1934.499928        97.79        Politician\n",
        "10             Henry Kissinger   91  1934.499928        94.70          Diplomat\n",
        "11             Bashar al-Assad   49  1934.499928        79.31        Politician\n",
        "12                Lee Kwan Yew   91  1934.499928        94.70        Politician\n",
        "31                 Fats Domino   86  1934.499928        91.38           Pianist\n",
        "22               Zsa Zsa Gabor   97  1934.499928        99.94           Actress\n",
        "21         Olivia de Havilland   98  1934.499928       100.76           Actress\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'ridge_regression' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-0b78b4c8301f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'ridge_regression' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lasso_regression(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'lasso_regression' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-2e46f808f26e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlasso_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'lasso_regression' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elastic_net(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lasso_lars(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'lasso_lars' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-d9a30446a0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlasso_lars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'lasso_lars' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bayseian_ridge(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ARD(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SGD_regression(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#poly(train_X,train_Y,test_X,test_Y) - takes long but working, can't understand the o/p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SVR(train_X,train_Y,test_X,test_Y) - many need to normalize to get this to work"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "KNN(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'KNN' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-10-f082e3cdd4fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'KNN' is not defined"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "decison_tree(train_X,train_Y,test_X,test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}